{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753639d1",
   "metadata": {},
   "source": [
    "# Challenge #13\n",
    "**Eric Zhou**  \n",
    "**April 25, 2025**\n",
    "\n",
    "# Introduction\n",
    "In Challenge 11, we explored GPU acceleration performance using the FrozenLake environment. We observed that GPU usage provides significant benefits, particularly when the code involves heavy multiplication and accumulation operations. Furthermore, as the problem size increases, the advantages of GPU acceleration become even more pronounced.\n",
    "\n",
    "In Challenge 13, we aim to dive deeper into GPU programming and optimization through the SAXPY problem. The learning objectives for this challenge include setting up and modifying example CUDA code, profiling and optimizing the implementation, and comparing and visualizing performance as the problem size increases.\n",
    "\n",
    "# SAXPY Problem\n",
    "\n",
    "In this challenge, we focus on the example code from [NVIDIA's Easy Introduction to CUDA C](https://developer.nvidia.com/blog/easy-introduction-cuda-c-and-c).\n",
    "\n",
    "SAXPY stands for **\"Single-precision A × X Plus Y\"** and serves as a classic \"hello world\" example for parallel computation.\n",
    "\n",
    "In the SAXPY operation, we have data Xi and Yi, each element \\( i \\) performs its own independent computation:\n",
    "\n",
    "\\[\n",
    "y[i] = a \\times x[i] + y[i]\n",
    "\\]\n",
    "\n",
    "There are no dependencies between elements, meaning each element can be computed independently and in parallel.\n",
    "\n",
    "\n",
    "# CUDA Kernel\n",
    "A kernel is a perfect fit because it can run many threads at once, with each thread assigned to one element. Since there are no dependencies between elements, all threads can safely work in parallel without needing to coordinate with each other. This perfectly matches how GPUs are designed — they are built to handle many simple, independent threads working simultaneously, making them ideal for parallel computing tasks like SAXPY.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fc94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Mar_21_19:24:09_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.58\n",
      "Build cuda_11.3.r11.3/compiler.29745058_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version # I have intalled the cuda compier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3d7107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc fatal   : Cannot find compiler 'cl.exe' in PATH\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o saxpy_benchmark saxpy_benchmark.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79258d68",
   "metadata": {},
   "source": [
    "I failed to run nvcc -o saxpy_benchmark saxpy_benchmark.cu and windows told me \n",
    "\n",
    ">nvcc fatal   : Cannot find compiler 'cl.exe' in PATH\n",
    "\n",
    "I checked with GPT and it told me I have to check back my C ++ installation in my computer. So I installed the Vscode C++ toolchain 2022 as it suggest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc561f4",
   "metadata": {},
   "source": [
    "Then I come to open your Windows start menu and Search: x64 Native Tools Command Prompt for VS 2022\n",
    "cd to your CUDA .cu file folder.\n",
    "\n",
    "Then compile:\n",
    "\n",
    "nvcc -o saxpy_benchmark saxpy_benchmark.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f114baa",
   "metadata": {},
   "source": [
    "D:\\AI4Hardware_ECE_410_2025_Spring\\Challenge_lists\\Challenge#13\\Code>nvcc -o saxpy_benchmark saxpy_benchmark.cu\n",
    "saxpy_benchmark.cu\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\include\\crt/host_config.h(160): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2019 (inclusive) are supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.\n",
    "\n",
    "D:\\AI4Hardware_ECE_410_2025_Spring\\Challenge_lists\\Challenge#13\\Code>nvcc -allow-unsupported-compiler -o saxpy_benchmark saxpy_benchmark.cu\n",
    "saxpy_benchmark.cu\n",
    "D:\\vscode_installation\\VC\\Tools\\MSVC\\14.43.34808\\include\\yvals_core.h(921): error: static assertion failed with \"error STL1002: Unexpected compiler version, expected CUDA 12.4 or newer.\"\n",
    "\n",
    "I met with problems above that indicate my version of cuda was too low. I check with the version of cuda that can support my old version of cude 11.3 was the vscode 2019, but I failed to install the 2019 version. My personal computer GPU version is Nvida T600, I checked with GPT and I think it fine to just upgrade my cuda to the newest one. I followed with GPT suggestion to upgrage my cuda software.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14723977",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
