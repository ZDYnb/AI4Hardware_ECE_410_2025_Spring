{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d07050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, 0): 0, (0, 0, 1): 0, (0, 0, 2): 0, (0, 0, 3): 0, (0, 1, 0): 0, (0, 1, 1): 0, (0, 1, 2): 0, (0, 1, 3): 0, (0, 2, 0): 0, (0, 2, 1): 0, (0, 2, 2): 0, (0, 2, 3): 0, (0, 3, 0): 0, (0, 3, 1): 0, (0, 3, 2): 0, (0, 3, 3): 0, (0, 4, 0): 0, (0, 4, 1): 0, (0, 4, 2): 0, (0, 4, 3): 0, (1, 0, 0): 0, (1, 0, 1): 0, (1, 0, 2): 0, (1, 0, 3): 0, (1, 1, 0): 0, (1, 1, 1): 0, (1, 1, 2): 0, (1, 1, 3): 0, (1, 2, 0): 0, (1, 2, 1): 0, (1, 2, 2): 0, (1, 2, 3): 0, (1, 3, 0): 0, (1, 3, 1): 0, (1, 3, 2): 0, (1, 3, 3): 0, (1, 4, 0): 0, (1, 4, 1): 0, (1, 4, 2): 0, (1, 4, 3): 0, (2, 0, 0): 0, (2, 0, 1): 0, (2, 0, 2): 0, (2, 0, 3): 0, (2, 1, 0): 0, (2, 1, 1): 0, (2, 1, 2): 0, (2, 1, 3): 0, (2, 2, 0): 0, (2, 2, 1): 0, (2, 2, 2): 0, (2, 2, 3): 0, (2, 3, 0): 0, (2, 3, 1): 0, (2, 3, 2): 0, (2, 3, 3): 0, (2, 4, 0): 0, (2, 4, 1): 0, (2, 4, 2): 0, (2, 4, 3): 0, (3, 0, 0): 0, (3, 0, 1): 0, (3, 0, 2): 0, (3, 0, 3): 0, (3, 1, 0): 0, (3, 1, 1): 0, (3, 1, 2): 0, (3, 1, 3): 0, (3, 2, 0): 0, (3, 2, 1): 0, (3, 2, 2): 0, (3, 2, 3): 0, (3, 3, 0): 0, (3, 3, 1): 0, (3, 3, 2): 0, (3, 3, 3): 0, (3, 4, 0): 0, (3, 4, 1): 0, (3, 4, 2): 0, (3, 4, 3): 0, (4, 0, 0): 0, (4, 0, 1): 0, (4, 0, 2): 0, (4, 0, 3): 0, (4, 1, 0): 0, (4, 1, 1): 0, (4, 1, 2): 0, (4, 1, 3): 0, (4, 2, 0): 0, (4, 2, 1): 0, (4, 2, 2): 0, (4, 2, 3): 0, (4, 3, 0): 0, (4, 3, 1): 0, (4, 3, 2): 0, (4, 3, 3): 0, (4, 4, 0): 0, (4, 4, 1): 0, (4, 4, 2): 0, (4, 4, 3): 0}\n",
      "{(0, 0, 0): -5.735, (0, 0, 1): -5.499, (0, 0, 2): -5.735, (0, 0, 3): -5.262, (0, 1, 0): -5.262, (0, 1, 1): -4.736, (0, 1, 2): -5.735, (0, 1, 3): -4.736, (0, 2, 0): -4.736, (0, 2, 1): -4.152, (0, 2, 2): -5.262, (0, 2, 3): -4.152, (0, 3, 0): -4.152, (0, 3, 1): -5.499, (0, 3, 2): -4.736, (0, 3, 3): -3.503, (0, 4, 0): -3.503, (0, 4, 1): -2.782, (0, 4, 2): -4.152, (0, 4, 3): -3.503, (1, 0, 0): -5, (1, 0, 1): -5, (1, 0, 2): -5, (1, 0, 3): -5, (1, 1, 0): -5.088, (1, 1, 1): -4.152, (1, 1, 2): -5.499, (1, 1, 3): -4.152, (1, 2, 0): -4.736, (1, 2, 1): -3.503, (1, 2, 2): -4.736, (1, 2, 3): -5.499, (1, 3, 0): -5, (1, 3, 1): -5, (1, 3, 2): -5, (1, 3, 3): -5, (1, 4, 0): -3.503, (1, 4, 1): -1.98, (1, 4, 2): -5.499, (1, 4, 3): -2.782, (2, 0, 0): -4.125, (2, 0, 1): -3.36, (2, 0, 2): -3.366, (2, 0, 3): -3.474, (2, 1, 0): -4.114, (2, 1, 1): -4.25, (2, 1, 2): -3.621, (2, 1, 3): -3.503, (2, 2, 0): -4.152, (2, 2, 1): -2.782, (2, 2, 2): -4.152, (2, 2, 3): -2.782, (2, 3, 0): -5.499, (2, 3, 1): -1.98, (2, 3, 2): -3.503, (2, 3, 3): -1.98, (2, 4, 0): -2.782, (2, 4, 1): -1.089, (2, 4, 2): -2.782, (2, 4, 3): -1.98, (3, 0, 0): -3.265, (3, 0, 1): -3.251, (3, 0, 2): -3.59, (3, 0, 3): -5.328, (3, 1, 0): -5, (3, 1, 1): -5, (3, 1, 2): -5, (3, 1, 3): -5, (3, 2, 0): -2.848, (3, 2, 1): -4.875, (3, 2, 2): -2.75, (3, 2, 3): -1.98, (3, 3, 0): -2.76, (3, 3, 1): -1.093, (3, 3, 2): -2.747, (3, 3, 3): -1.089, (3, 4, 0): -1.98, (3, 4, 1): -0.099, (3, 4, 2): -1.98, (3, 4, 3): -1.089, (4, 0, 0): -3.371, (4, 0, 1): -2.842, (4, 0, 2): -3.017, (4, 0, 3): -3.046, (4, 1, 0): -4.125, (4, 1, 1): -3.017, (4, 1, 2): -2.891, (4, 1, 3): -4.125, (4, 2, 0): -5, (4, 2, 1): -5, (4, 2, 2): -5, (4, 2, 3): -5, (4, 3, 0): -0.855, (4, 3, 1): -0.5, (4, 3, 2): -2.75, (4, 3, 3): -0.1, (4, 4, 0): 1, (4, 4, 1): 1, (4, 4, 2): 1, (4, 4, 3): 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "| -5.262 | -4.736 | -4.152 | -3.503 | -2.782 | \n",
      "-----------------------------------------------\n",
      "| -5     | -4.152 | -3.503 | -5     | -1.98  | \n",
      "-----------------------------------------------\n",
      "| -3.36  | -3.503 | -2.782 | -1.98  | -1.089 | \n",
      "-----------------------------------------------\n",
      "| -3.251 | -5     | -1.98  | -1.089 | -0.099 | \n",
      "-----------------------------------------------\n",
      "| -2.842 | -2.891 | -5     | -0.1   | 1      | \n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# original code from https://github.com/ronanmmurphy/Q-Learning-Algorithm/blob/main/Q-Learning%20Algorithm.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 28 12:59:23 2020\n",
    "\n",
    "Assignment 2 - Agents and Reinforcement Learning\n",
    "\n",
    "@author: Ronan Murphy - 15397831\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#set the rows and columns length\n",
    "BOARD_ROWS = 5\n",
    "BOARD_COLS = 5\n",
    "\n",
    "#initalise start, win and lose states\n",
    "START = (0, 0)\n",
    "WIN_STATE = (4, 4)\n",
    "HOLE_STATE = [(1,0),(3,1),(4,2),(1,3)]\n",
    "\n",
    "#class state defines the board and decides reward, end and next position\n",
    "class State:\n",
    "    def __init__(self, state=START):\n",
    "        #initalise the state to start and end to false\n",
    "        self.state = state\n",
    "        self.isEnd = False        \n",
    "\n",
    "    def getReward(self):\n",
    "        #give the rewards for each state -5 for loss, +1 for win, -1 for others\n",
    "        for i in HOLE_STATE:\n",
    "            if self.state == i:\n",
    "                return -5\n",
    "        if self.state == WIN_STATE:\n",
    "            return 1       \n",
    "        \n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def isEndFunc(self):\n",
    "        #set state to end if win/loss\n",
    "        if (self.state == WIN_STATE):\n",
    "            self.isEnd = True\n",
    "            \n",
    "        for i in HOLE_STATE:\n",
    "            if self.state == i:\n",
    "                self.isEnd = True\n",
    "\n",
    "    def nxtPosition(self, action):     \n",
    "        #set the positions from current action - up, down, left, right\n",
    "        if action == 0:                \n",
    "            nxtState = (self.state[0] - 1, self.state[1]) #up             \n",
    "        elif action == 1:\n",
    "            nxtState = (self.state[0] + 1, self.state[1]) #down\n",
    "        elif action == 2:\n",
    "            nxtState = (self.state[0], self.state[1] - 1) #left\n",
    "        else:\n",
    "            nxtState = (self.state[0], self.state[1] + 1) #right\n",
    "\n",
    "\n",
    "        #check if next state is possible\n",
    "        if (nxtState[0] >= 0) and (nxtState[0] <= 4):\n",
    "            if (nxtState[1] >= 0) and (nxtState[1] <= 4):    \n",
    "                    #if possible change to next state                \n",
    "                    return nxtState \n",
    "        #Return current state if outside grid     \n",
    "        return self.state \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#class agent to implement reinforcement learning through grid  \n",
    "class Agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        #inialise states and actions \n",
    "        self.states = []\n",
    "        self.actions = [0,1,2,3]    # up, down, left, right\n",
    "        self.State = State()\n",
    "        #set the learning and greedy values\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 0.1\n",
    "        self.isEnd = self.State.isEnd\n",
    "\n",
    "        # array to retain reward values for plot\n",
    "        self.plot_reward = []\n",
    "        \n",
    "        #initalise Q values as a dictionary for current and new\n",
    "        self.Q = {}\n",
    "        self.new_Q = {}\n",
    "        #initalise rewards to 0\n",
    "        self.rewards = 0\n",
    "        \n",
    "        #initalise all Q values across the board to 0, print these values\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                for k in range(len(self.actions)):\n",
    "                    self.Q[(i, j, k)] =0\n",
    "                    self.new_Q[(i, j, k)] = 0\n",
    "        \n",
    "        print(self.Q)\n",
    "        \n",
    "    \n",
    "\n",
    "    #method to choose action with Epsilon greedy policy, and move to next state\n",
    "    def Action(self):\n",
    "        #random value vs epsilon\n",
    "        rnd = random.random()\n",
    "        #set arbitraty low value to compare with Q values to find max\n",
    "        mx_nxt_reward =-10\n",
    "        action = None\n",
    "        \n",
    "        #9/10 find max Q value over actions \n",
    "        if(rnd >self.epsilon) :\n",
    "            #iterate through actions, find Q  value and choose best \n",
    "            for k in self.actions:\n",
    "                \n",
    "                i,j = self.State.state\n",
    "                \n",
    "                nxt_reward = self.Q[(i,j, k)]\n",
    "                \n",
    "                if nxt_reward >= mx_nxt_reward:\n",
    "                    action = k\n",
    "                    mx_nxt_reward = nxt_reward\n",
    "                    \n",
    "        #else choose random action\n",
    "        else:\n",
    "            action = np.random.choice(self.actions)\n",
    "        \n",
    "        #select the next state based on action chosen\n",
    "        position = self.State.nxtPosition(action)\n",
    "        return position,action\n",
    "    \n",
    "    \n",
    "    #Q-learning Algorithm\n",
    "    def Q_Learning(self,episodes):\n",
    "        x = 0\n",
    "        #iterate through best path for each episode\n",
    "        while(x < episodes):\n",
    "            #check if state is end\n",
    "            if self.isEnd:\n",
    "                #get current rewrard and add to array for plot\n",
    "                reward = self.State.getReward()\n",
    "                self.rewards += reward\n",
    "                self.plot_reward.append(self.rewards)\n",
    "                \n",
    "                #get state, assign reward to each Q_value in state\n",
    "                i,j = self.State.state\n",
    "                for a in self.actions:\n",
    "                    self.new_Q[(i,j,a)] = round(reward,3)\n",
    "                    \n",
    "                #reset state\n",
    "                self.State = State()\n",
    "                self.isEnd = self.State.isEnd\n",
    "                \n",
    "                #set rewards to zero and iterate to next episode\n",
    "                self.rewards = 0\n",
    "                x+=1\n",
    "            else:\n",
    "                #set to arbitrary low value to compare net state actions\n",
    "                mx_nxt_value = -10\n",
    "                #get current state, next state, action and current reward\n",
    "                next_state, action = self.Action()\n",
    "                i,j = self.State.state\n",
    "                reward = self.State.getReward()\n",
    "                #add reward to rewards for plot\n",
    "                self.rewards +=reward\n",
    "                \n",
    "                #iterate through actions to find max Q value for action based on next state action\n",
    "                for a in self.actions:\n",
    "                    nxtStateAction = (next_state[0], next_state[1], a)\n",
    "                    q_value = (1-self.alpha)*self.Q[(i,j,action)] + self.alpha*(reward + self.gamma*self.Q[nxtStateAction])\n",
    "                \n",
    "                    #find largest Q value\n",
    "                    if q_value >= mx_nxt_value:\n",
    "                        mx_nxt_value = q_value\n",
    "                \n",
    "                #next state is now current state, check if end state\n",
    "                self.State = State(state=next_state)\n",
    "                self.State.isEndFunc()\n",
    "                self.isEnd = self.State.isEnd\n",
    "                \n",
    "                #update Q values with max Q value for next state\n",
    "                self.new_Q[(i,j,action)] = round(mx_nxt_value,3)\n",
    "            \n",
    "            #copy new Q values to Q table\n",
    "            self.Q = self.new_Q.copy()\n",
    "        #print final Q table output\n",
    "        print(self.Q)\n",
    "        \n",
    "    #plot the reward vs episodes\n",
    "    def plot(self,episodes):\n",
    "        \n",
    "        plt.plot(self.plot_reward)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    #iterate through the board and find largest Q value in each, print output\n",
    "    def showValues(self):\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-----------------------------------------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                mx_nxt_value = -10\n",
    "                for a in self.actions:\n",
    "                    nxt_value = self.Q[(i,j,a)]\n",
    "                    if nxt_value >= mx_nxt_value:\n",
    "                        mx_nxt_value = nxt_value\n",
    "                out += str(mx_nxt_value).ljust(6) + ' | '\n",
    "            print(out)\n",
    "        print('-----------------------------------------------')\n",
    "        \n",
    "    \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    #create agent for 10,000 episdoes implementing a Q-learning algorithm plot and show values.\n",
    "    ag = Agent()\n",
    "    episodes = 10000\n",
    "    ag.Q_Learning(episodes)\n",
    "    ag.plot(episodes)\n",
    "    ag.showValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff261425",
   "metadata": {},
   "source": [
    "I also ask for some explanation for this code analysis:\n",
    "\n",
    "> # 🧠 What is this Q-Learning source code doing?\n",
    ">\n",
    "> **Overall goal:**  \n",
    "> Train an **agent** to navigate a 5x5 FrozenLake grid using **Q-Learning** to reach the **WIN_STATE** while avoiding the **HOLE_STATE** (holes).\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # ✨ Detailed Explanation by Module\n",
    ">\n",
    "> | Module | Description |\n",
    "> |:---|:---|\n",
    "> | `State` class | Manages the agent's current position (`self.state`), checks if the game is over (`self.isEnd`), returns rewards (`getReward`), and computes next position based on actions (`nxtPosition`). |\n",
    "> | `Agent` class | Implements Q-Learning: initializes the Q-table, chooses actions (epsilon-greedy), updates Q-values, records rewards, and plots learning progress. |\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> ## 1. `State` class details\n",
    "> - **Initialization** ➔ Starts at `(0,0)`.\n",
    "> - **`getReward()`**:\n",
    ">   - If agent falls into a HOLE → reward = **-5**\n",
    ">   - If agent reaches WIN → reward = **+1**\n",
    ">   - Otherwise (normal move) → reward = **-1**\n",
    "> - **`isEndFunc()`**:\n",
    ">   - Sets `isEnd = True` if the agent reaches the WIN or a HOLE.\n",
    "> - **`nxtPosition(action)`**:\n",
    ">   - Computes the next position based on the action (up, down, left, right).\n",
    ">   - If the next position is out of bounds, stay at the current position.\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> ## 2. `Agent` class details\n",
    "> - **Actions defined**: 0 = up, 1 = down, 2 = left, 3 = right.\n",
    "> - **Parameters**:\n",
    ">   - `alpha = 0.5` ➔ Learning rate\n",
    ">   - `gamma = 0.9` ➔ Discount factor\n",
    ">   - `epsilon = 0.1` ➔ 10% chance to explore randomly\n",
    "> - **Q-table structure**:\n",
    ">   - `self.Q[(i, j, k)]`\n",
    ">     - (i, j) = board position\n",
    ">     - k = action\n",
    ">     - Each position and action has a separate Q-value.\n",
    "> - **new_Q table**:\n",
    ">   - A temporary table for updating values safely before copying back to `self.Q`.\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> ## 3. Core Methods\n",
    ">\n",
    "> ### ➔ `Action()`\n",
    "> - **Epsilon-greedy strategy**:\n",
    ">   - 90% of the time choose the best known action (highest Q-value).\n",
    ">   - 10% of the time pick a random action.\n",
    ">\n",
    "> ### ➔ `Q_Learning(episodes)`\n",
    "> Main training loop — **one episode means navigating from start until reaching WIN or HOLE**.\n",
    ">\n",
    "> Main logic:\n",
    ">\n",
    "> 1. **If the state is terminal** (WIN or HOLE):\n",
    ">    - Assign the terminal reward directly to all Q-values at the current state.\n",
    ">    - Reset to start a new episode.\n",
    "> 2. **If not terminal**:\n",
    ">    - Choose an action with epsilon-greedy.\n",
    ">    - Get the reward for the current state.\n",
    ">    - Look ahead: find the maximum Q-value at the next state.\n",
    ">    - Update the Q-value using the Q-Learning update rule:\n",
    ">\n",
    ">    ```\n",
    ">    Q(s,a) ← (1-α) × Q(s,a) + α × (r + γ × max_a Q(s',a))\n",
    ">    ```\n",
    ">    - Move to the next state.\n",
    "> 3. **At the end of every step**, copy `new_Q` back into `self.Q`.\n",
    ">\n",
    "> ### ➔ `plot(episodes)`\n",
    "> - Plot cumulative rewards vs. number of episodes.\n",
    ">\n",
    "> ### ➔ `showValues()`\n",
    "> - Print the maximum Q-value for each board position after training to visualize the learned policy.\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # 🔥 Key Points\n",
    ">\n",
    "> | Key Concept | Explanation |\n",
    "> |:---|:---|\n",
    "> | Q-table uses a dictionary | `(row, col, action)` as key |\n",
    "> | new_Q is used for safe updating | To avoid corrupting current Q during training |\n",
    "> | ε-greedy action selection | 90% exploit, 10% random exploration |\n",
    "> | Rewards are designed carefully | +1 for reaching goal, -5 for falling into a hole, -1 for normal moves |\n",
    "> | Clear episode ending condition | Episode ends when reaching WIN or HOLE |\n",
    "> | Full Q-table copy every episode | (This could be optimized later) |\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # 🎯 Why is this code a little confusing?\n",
    ">\n",
    "> You're right — it feels a bit messy because:\n",
    "> - The code uses **dictionaries** instead of clean matrices (harder to visualize).\n",
    "> - **new_Q** and **Q** copying back and forth makes tracking updates tricky.\n",
    "> - **Action selection and reward calculation** are bundled together, not modularized.\n",
    "> - **No function decomposition** — everything happens inside one big method (`Q_Learning()`).\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # 🧹 Visualizing it as a Simple Flowchart\n",
    ">\n",
    "> ```\n",
    "> Start (state = (0,0))\n",
    ">\n",
    "> ↓\n",
    "> Choose action (epsilon-greedy)\n",
    ">\n",
    "> ↓\n",
    "> Move to new state (nxtPosition)\n",
    ">\n",
    "> ↓\n",
    "> Get reward based on new position\n",
    ">\n",
    "> ↓\n",
    "> Update Q-table (Q-Learning formula)\n",
    ">\n",
    "> ↓\n",
    "> If reached WIN or HOLE?\n",
    ">  ↙              ↘\n",
    "> Yes             No\n",
    "> ↓                ↓\n",
    "> Reset episode   Keep moving\n",
    "> ```\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # ✨ Pro Tips\n",
    ">\n",
    "> If you want to **trace and debug** how the agent is learning, you can add simple `print()` statements, for example:\n",
    ">\n",
    "> ```python\n",
    "> print(f\"State: {self.State.state}, Action: {action}, Reward: {reward}\")\n",
    "> ```\n",
    ">\n",
    "> This way you can watch how the agent moves and updates values during training.\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> # ✅ Full Summary\n",
    ">\n",
    "> **This code trains an agent using Q-Learning to move across a 5x5 FrozenLake grid, aiming to reach the WIN state while avoiding holes, learning an optimal path through trial and error.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d36746",
   "metadata": {},
   "source": [
    "In each episode, the agent takes multiple steps. After each move to a new position, it updates the Q-table based on the received reward. This updated Q-table serves as feedback, gradually guiding the agent to learn better paths through the environment using the Q-learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d6f88",
   "metadata": {},
   "source": [
    "Part 1: Identify the comparable logic\n",
    "Let’s isolate the most important Q-learning update rule from your Python code:\n",
    "\n",
    "q_value = (1 - alpha) * Q[(i,j,action)] + alpha * (reward + gamma * Q[(next_i, next_j, a)])\n",
    "Your Verilog code implements this using fixed-point math. So, the goal is to test:\n",
    "\n",
    "For a given (s, a, s', r) input tuple,\n",
    "\n",
    "The Verilog and Python modules should produce the same (or very close) new Q(s,a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2599110",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee09756e",
   "metadata": {},
   "source": [
    "Create a Python script that exports Q-update test vectors to a file for Verilog testbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3c1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# fixed test input\n",
    "alpha = 0.5\n",
    "gamma = 0.9\n",
    "\n",
    "# test data\n",
    "test_cases = [\n",
    "    # curr_row, curr_col, curr_action, next_row, next_col, reward, Q(s,a), max_a(Q(s'))\n",
    "    (1, 1, 2, 2, 2, -1, 0.5, 0.9),\n",
    "    (0, 0, 1, 0, 1, -1, 0.2, 0.4),\n",
    "    (2, 3, 3, 4, 4, 1, 0.0, 1.0),\n",
    "    (4, 2, 0, 4, 3, -5, 0.8, 0.3),\n",
    "]\n",
    "\n",
    "with open(\"test_vectors.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"s_row\", \"s_col\", \"action\", \"next_row\", \"next_col\", \"reward\", \"Q_sa\", \"Q_max_next\"])\n",
    "    for case in test_cases:\n",
    "        writer.writerow(case)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16199aa",
   "metadata": {},
   "source": [
    "Create a Verilog testbench (tb_q_update_unit.sv) that:\n",
    "Reads values from a file;\n",
    "Applies them to the DUT (your q_update_unit);\n",
    "Captures output Q′;\n",
    "Logs results for comparison;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "module tb_q_update_unit;\n",
    "\n",
    "    // Parameters\n",
    "    parameter Q_WIDTH = 16;\n",
    "\n",
    "    // DUT inputs\n",
    "    logic clk = 0, rst = 0, start = 0;\n",
    "    logic [2:0] curr_row, curr_col, next_row, next_col;\n",
    "    logic [1:0] curr_action;\n",
    "    logic signed [Q_WIDTH-1:0] reward;\n",
    "\n",
    "    // DUT output\n",
    "    logic done;\n",
    "\n",
    "    // Instantiate DUT\n",
    "    q_update_unit dut (\n",
    "        .clk(clk), .rst(rst), .start(start),\n",
    "        .curr_row(curr_row), .curr_col(curr_col),\n",
    "        .curr_action(curr_action), .reward(reward),\n",
    "        .next_row(next_row), .next_col(next_col),\n",
    "        .done(done)\n",
    "    );\n",
    "\n",
    "    // Clock\n",
    "    always #5 clk = ~clk;\n",
    "\n",
    "    initial begin\n",
    "        $display(\"Starting Verilog test...\");\n",
    "\n",
    "        // Read from test_vectors.csv converted to .mem or .hex if needed\n",
    "        // OR hardcode a few vectors here for testing\n",
    "\n",
    "        // Example test\n",
    "        rst = 1; #10; rst = 0;\n",
    "        curr_row = 3;\n",
    "        curr_col = 2;\n",
    "        curr_action = 1;\n",
    "        next_row = 3;\n",
    "        next_col = 3;\n",
    "        reward = -16'd1;  // Fixed-point representation\n",
    "\n",
    "        start = 1; #10; start = 0;\n",
    "\n",
    "        wait (done == 1);\n",
    "        $display(\"Test completed\");\n",
    "        $finish;\n",
    "    end\n",
    "endmodule\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (joyrl-book)",
   "language": "python",
   "name": "joyrl-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
